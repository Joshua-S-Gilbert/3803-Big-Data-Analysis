{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "executionInfo": {
     "elapsed": 290,
     "status": "error",
     "timestamp": 1709470131849,
     "user": {
      "displayName": "Minh Hiếu Nguyễn",
      "userId": "03728514655365313772"
     },
     "user_tz": -600
    },
    "id": "P8t19yNDV_DG",
    "outputId": "ea1d882b-238d-4853-889d-d40a47728e0c"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot parse from 'Response'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 57\u001b[0m\n\u001b[0;32m     53\u001b[0m     get_movies(url)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 57\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[45], line 53\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m     52\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.imdb.com/chart/top\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 53\u001b[0m     get_movies(url)\n",
      "Cell \u001b[1;32mIn[45], line 19\u001b[0m, in \u001b[0;36mget_movies\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     15\u001b[0m soup_imdb \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m all_movies \u001b[38;5;241m=\u001b[39m soup_imdb\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mli\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipc-metadata-list-summary-item\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m---> 19\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_html(requests\u001b[38;5;241m.\u001b[39mget(url, headers\u001b[38;5;241m=\u001b[39mheaders))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:1245\u001b[0m, in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[0m\n\u001b[0;32m   1229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m   1230\u001b[0m     [\n\u001b[0;32m   1231\u001b[0m         is_file_like(io),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1235\u001b[0m     ]\n\u001b[0;32m   1236\u001b[0m ):\n\u001b[0;32m   1237\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1238\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing literal html to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread_html\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1239\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. To read from a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1242\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1243\u001b[0m     )\n\u001b[1;32m-> 1245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parse(\n\u001b[0;32m   1246\u001b[0m     flavor\u001b[38;5;241m=\u001b[39mflavor,\n\u001b[0;32m   1247\u001b[0m     io\u001b[38;5;241m=\u001b[39mio,\n\u001b[0;32m   1248\u001b[0m     match\u001b[38;5;241m=\u001b[39mmatch,\n\u001b[0;32m   1249\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   1250\u001b[0m     index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m   1251\u001b[0m     skiprows\u001b[38;5;241m=\u001b[39mskiprows,\n\u001b[0;32m   1252\u001b[0m     parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[0;32m   1253\u001b[0m     thousands\u001b[38;5;241m=\u001b[39mthousands,\n\u001b[0;32m   1254\u001b[0m     attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1255\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   1256\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   1257\u001b[0m     converters\u001b[38;5;241m=\u001b[39mconverters,\n\u001b[0;32m   1258\u001b[0m     na_values\u001b[38;5;241m=\u001b[39mna_values,\n\u001b[0;32m   1259\u001b[0m     keep_default_na\u001b[38;5;241m=\u001b[39mkeep_default_na,\n\u001b[0;32m   1260\u001b[0m     displayed_only\u001b[38;5;241m=\u001b[39mdisplayed_only,\n\u001b[0;32m   1261\u001b[0m     extract_links\u001b[38;5;241m=\u001b[39mextract_links,\n\u001b[0;32m   1262\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1263\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   1264\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:988\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    977\u001b[0m p \u001b[38;5;241m=\u001b[39m parser(\n\u001b[0;32m    978\u001b[0m     io,\n\u001b[0;32m    979\u001b[0m     compiled_match,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    984\u001b[0m     storage_options,\n\u001b[0;32m    985\u001b[0m )\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 988\u001b[0m     tables \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mparse_tables()\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m caught:\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;66;03m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;66;03m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[0;32m    992\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(io, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseekable\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m io\u001b[38;5;241m.\u001b[39mseekable():\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:248\u001b[0m, in \u001b[0;36m_HtmlFrameParser.parse_tables\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_tables\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    241\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;124;03m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m     tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_tables(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_doc(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrs)\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_thead_tbody_tfoot(table) \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:796\u001b[0m, in \u001b[0;36m_LxmlFrameParser._build_doc\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    793\u001b[0m         r \u001b[38;5;241m=\u001b[39m parse(f\u001b[38;5;241m.\u001b[39mhandle, parser\u001b[38;5;241m=\u001b[39mparser)\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    795\u001b[0m     \u001b[38;5;66;03m# try to parse the input in the simplest way\u001b[39;00m\n\u001b[1;32m--> 796\u001b[0m     r \u001b[38;5;241m=\u001b[39m parse(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio, parser\u001b[38;5;241m=\u001b[39mparser)\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    798\u001b[0m     r \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mgetroot()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lxml\\html\\__init__.py:937\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(filename_or_url, parser, base_url, **kw)\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parser \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    936\u001b[0m     parser \u001b[38;5;241m=\u001b[39m html_parser\n\u001b[1;32m--> 937\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m etree\u001b[38;5;241m.\u001b[39mparse(filename_or_url, parser, base_url\u001b[38;5;241m=\u001b[39mbase_url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32msrc/lxml/etree.pyx:3541\u001b[0m, in \u001b[0;36mlxml.etree.parse\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc/lxml/parser.pxi:1902\u001b[0m, in \u001b[0;36mlxml.etree._parseDocument\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot parse from 'Response'"
     ]
    }
   ],
   "source": [
    "# Write a Python script to download IMDB 250 Top Rated Movies.\n",
    "# For each movie, you'll need to retrieve the movie title, the ranking, the initial release year, the casting and\n",
    "# the rating.\n",
    "# Your data must be stored in a proper imdb_top_250.csv file.\n",
    "\n",
    "import requests, csv\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def get_movies(url):\n",
    "    user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.6167.186 Safari/537.36\"\n",
    "    headers = {\"User-Agent\": user_agent}\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup_imdb = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    all_movies = soup_imdb.find_all(\"li\", {\"class\":\"ipc-metadata-list-summary-item\"})\n",
    "\n",
    "    df = pd.read_html(requests.get(url, headers=headers))\n",
    "    # get movie title :\n",
    "    # all_movies_soup = BeautifulSoup(\n",
    "    # titles = \n",
    "    # print(all_movies)\n",
    "    # for movie in all_movies:\n",
    "    #     movie_html = \n",
    "    #     print(movie_html)\n",
    "    #     break\n",
    "    \n",
    "\n",
    "    # get ranking :\n",
    "    #rankings =\n",
    "\n",
    "    # get release year :\n",
    "    #years =\n",
    "\n",
    "    # get rating :\n",
    "    #ratings =\n",
    "\n",
    "    #mega_list = list(zip(titles, rankings, years, ratings))\n",
    "    #mega_list = [list(elt) for elt in mega_list]\n",
    "\n",
    "    # Write csv\n",
    "    #str_lst = [f\"{mega_list[i][1]} / {mega_list[i][0]} ({mega_list[i][2]}) / Starring: {mega_list[i][3]}\" \\\n",
    "    #for i, val in enumerate(mega_list)]\n",
    "\n",
    "    #res = [elt.split(\"/\") for elt in str_lst]\n",
    "\n",
    "    #with open(\"imdb_top_250.csv\", \"w\") as f:\n",
    "        #writer = csv.writer(f, delimiter=\"-\")\n",
    "        #writer.writerows(res)\n",
    "def main():\n",
    "    url = \"https://www.imdb.com/chart/top\"\n",
    "    get_movies(url)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4lWsqTtWV_DL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
